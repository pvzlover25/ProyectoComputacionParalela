{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsyu7NIRe_aP",
        "outputId": "156fe4ac-daf1-48f1-bfbc-2b7d4f24eb97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        target. The options -dlto -arch=sm_NN will add a lto_NN target; if you want\n",
            "        to only add a lto_NN target and not the compute_NN that -arch=sm_NN usually\n",
            "        for '--gpu-architecture' may be a 'real' architecture (such as a sm_50),\n",
            "        --gpu-architecture=sm_50' is equivalent to 'nvcc --gpu-architecture=compute_50\n",
            "        --gpu-code=sm_50,compute_50'.\n",
            "        -arch=all         build for all supported architectures (sm_*), and add PTX\n",
            "        -arch=all-major   build for just supported major versions (sm_*0), plus the\n",
            "        -arch=native      build for all architectures (sm_*) on the current system\n",
            "        'native','sm_50','sm_52','sm_53','sm_60','sm_61','sm_62','sm_70','sm_72',\n",
            "        'sm_75','sm_80','sm_86','sm_87','sm_89','sm_90','sm_90a'.\n",
            "        (such as sm_50), and PTX code for the 'virtual' architecture (such as compute_50).\n",
            "        For instance, '--gpu-architecture=compute_60' is not compatible with '--gpu-code=sm_52',\n",
            "        features that are not present on 'sm_52'.\n",
            "        'lto_75','lto_80','lto_86','lto_87','lto_89','lto_90','lto_90a','sm_50',\n",
            "        'sm_52','sm_53','sm_60','sm_61','sm_62','sm_70','sm_72','sm_75','sm_80',\n",
            "        'sm_86','sm_87','sm_89','sm_90','sm_90a'.\n",
            "        List the non-accelerated gpu architectures (sm_XX) supported by the compiler\n"
          ]
        }
      ],
      "source": [
        "!nvcc --help | grep sm_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2xDY0WSfKPY",
        "outputId": "1c0de9b8-afc0-4fc5-fb59-aaba77bf377b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul  9 20:42:26 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile quicksort.cu\n",
        "#include <iostream>\n",
        "#include <stack>\n",
        "#include <vector>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/copy.h>\n",
        "#include <thrust/scan.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <thrust/execution_policy.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "struct Rango{\n",
        "  int inicio,fin;\n",
        "};\n",
        "\n",
        "//Kernel para marcar los elementos segun el pivote\n",
        "struct menorQue{\n",
        "  int pivote;\n",
        "  __host__ __device__ menorQue(int p):pivote(p){}\n",
        "  __host__ __device__ bool operator()(int x) const{\n",
        "    return (x<pivote);\n",
        "  }\n",
        "};\n",
        "struct igualA{\n",
        "  int pivote;\n",
        "  __host__ __device__ igualA(int p):pivote(p){}\n",
        "  __host__ __device__ bool operator()(int x) const{\n",
        "    return (x==pivote);\n",
        "  }\n",
        "};\n",
        "struct mayorQue{\n",
        "  __host__ __device__\n",
        "  int operator()(int esMenor, int esIgual) const{\n",
        "    return !(esMenor||esIgual);\n",
        "  }\n",
        "};\n",
        "\n",
        "void printArray(vector<int> vec){\n",
        "  for(int i=0;i<vec.size();i++) cout<<vec[i]<<\" \";\n",
        "  cout<<\"\\n\";\n",
        "}\n",
        "\n",
        "void quicksort(thrust::device_vector<int> &d_arr){\n",
        "  int arr_size=d_arr.size();\n",
        "  thrust::device_vector<int> d_buffer(arr_size);\n",
        "  stack<Rango> rg_stack;\n",
        "  rg_stack.push({0,arr_size-1});\n",
        "  while(!rg_stack.empty()){\n",
        "    Rango rg=rg_stack.top();\n",
        "    rg_stack.pop();\n",
        "    int rg_size=rg.fin-rg.inicio+1;\n",
        "    if(rg_size<=1) continue;\n",
        "    int pivote=d_arr[rg.fin];\n",
        "    thrust::device_vector<int> lessFlags(rg_size),equalFlags(rg_size),greaterFlags(rg_size);\n",
        "    thrust::device_vector<int> lessPos(rg_size),equalPos(rg_size),greaterPos(rg_size);\n",
        "    auto begin=d_arr.begin()+rg.inicio;\n",
        "    auto finish=d_arr.begin()+rg.fin+1;\n",
        "    thrust::transform(begin,finish,lessFlags.begin(),menorQue(pivote));\n",
        "    thrust::transform(begin,finish,equalFlags.begin(),igualA(pivote));\n",
        "    thrust::transform(\n",
        "      lessFlags.begin(),\n",
        "      lessFlags.end(),\n",
        "      equalFlags.begin(),\n",
        "      greaterFlags.begin(),\n",
        "      mayorQue()\n",
        "    );\n",
        "    thrust::exclusive_scan(lessFlags.begin(),lessFlags.end(),lessPos.begin());\n",
        "    thrust::exclusive_scan(equalFlags.begin(),equalFlags.end(),equalPos.begin());\n",
        "    thrust::exclusive_scan(greaterFlags.begin(),greaterFlags.end(),greaterPos.begin());\n",
        "    int numMenor=thrust::reduce(lessFlags.begin(),lessFlags.end());\n",
        "    int numIgual=thrust::reduce(equalFlags.begin(),equalFlags.end());\n",
        "    for(int i=0;i<rg_size;i++){\n",
        "      int val=d_arr[rg.inicio+i];\n",
        "      if(lessFlags[i]){\n",
        "        int indice=rg.inicio+lessPos[i];\n",
        "        d_buffer[indice]=val;\n",
        "      }else if(equalFlags[i]){\n",
        "        int indice=rg.inicio+numMenor+equalPos[i];\n",
        "        d_buffer[indice]=val;\n",
        "      }else{\n",
        "        int indice=rg.inicio+numMenor+numIgual+greaterPos[i];\n",
        "        d_buffer[indice]=val;\n",
        "      }\n",
        "    }\n",
        "    thrust::copy(\n",
        "      d_buffer.begin()+rg.inicio,\n",
        "      d_buffer.begin()+rg.fin+1,\n",
        "      d_arr.begin()+rg.inicio\n",
        "    );\n",
        "    if(numMenor>1) rg_stack.push({rg.inicio,rg.inicio+numMenor-1});\n",
        "    if(rg_size-numMenor-numIgual>1) rg_stack.push({rg.inicio+numMenor+numIgual,rg.fin});\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  srand(time(NULL));\n",
        "  int size=atoi(argv[1]);\n",
        "  vector<int> arr;\n",
        "  for(int i=0;i<size;i++) arr.push_back(1+rand()%200);\n",
        "  auto start=chrono::high_resolution_clock::now();\n",
        "  thrust::device_vector<int> d_arr(arr.begin(),arr.end());\n",
        "  quicksort(d_arr);\n",
        "  thrust::copy(d_arr.begin(),d_arr.end(),arr.begin());\n",
        "  auto finish=chrono::high_resolution_clock::now();\n",
        "  auto duration=chrono::duration_cast<chrono::nanoseconds>(finish - start).count();\n",
        "  cout<<\"Tiempo demorado en ordenar arreglo: \"<<duration/1000000000.0<<\" s\\n\";\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--df2bo8fOSW",
        "outputId": "3107acd9-5e63-417e-929d-788851a9a174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing quicksort.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 quicksort.cu -o quicksort"
      ],
      "metadata": {
        "id": "H__N2__2fmYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./quicksort 2048"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwmoypyg0y36",
        "outputId": "9ebe9c58-f905-4751-f444-08e583c207d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo demorado en ordenar arreglo: 0.782673 s\n"
          ]
        }
      ]
    }
  ]
}