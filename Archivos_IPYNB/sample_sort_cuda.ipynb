{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RkrO0WFdLut",
        "outputId": "db2cbe4e-8d1e-4170-c7d9-0aac4994044c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        target. The options -dlto -arch=sm_NN will add a lto_NN target; if you want\n",
            "        to only add a lto_NN target and not the compute_NN that -arch=sm_NN usually\n",
            "        for '--gpu-architecture' may be a 'real' architecture (such as a sm_50),\n",
            "        --gpu-architecture=sm_50' is equivalent to 'nvcc --gpu-architecture=compute_50\n",
            "        --gpu-code=sm_50,compute_50'.\n",
            "        -arch=all         build for all supported architectures (sm_*), and add PTX\n",
            "        -arch=all-major   build for just supported major versions (sm_*0), plus the\n",
            "        -arch=native      build for all architectures (sm_*) on the current system\n",
            "        'native','sm_50','sm_52','sm_53','sm_60','sm_61','sm_62','sm_70','sm_72',\n",
            "        'sm_75','sm_80','sm_86','sm_87','sm_89','sm_90','sm_90a'.\n",
            "        (such as sm_50), and PTX code for the 'virtual' architecture (such as compute_50).\n",
            "        For instance, '--gpu-architecture=compute_60' is not compatible with '--gpu-code=sm_52',\n",
            "        features that are not present on 'sm_52'.\n",
            "        'lto_75','lto_80','lto_86','lto_87','lto_89','lto_90','lto_90a','sm_50',\n",
            "        'sm_52','sm_53','sm_60','sm_61','sm_62','sm_70','sm_72','sm_75','sm_80',\n",
            "        'sm_86','sm_87','sm_89','sm_90','sm_90a'.\n",
            "        List the non-accelerated gpu architectures (sm_XX) supported by the compiler\n"
          ]
        }
      ],
      "source": [
        "!nvcc --help | grep sm_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYUid7mNf-uk",
        "outputId": "ecd26ce1-9d50-4532-86ad-2dca0755d4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  8 21:32:53 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sample_sort.cu\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "#include <unordered_set>\n",
        "#include <vector>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/sort.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/scan.h>\n",
        "#include <thrust/iterator/constant_iterator.h>\n",
        "\n",
        "using namespace std;\n",
        "const int THRESHOLD=16;\n",
        "\n",
        "void printArray(vector<int> &arr){\n",
        "  for(int i=0;i<arr.size();i++) cout<<arr[i]<<\" \";\n",
        "  cout<<\"\\n\";\n",
        "}\n",
        "\n",
        "int getMin(int a, int b){\n",
        "  if(a<b) return a;\n",
        "  return b;\n",
        "}\n",
        "\n",
        "vector<int> randSample(vector<int> &arr, int s){\n",
        "  vector<int> ret;\n",
        "  unordered_set<int> miSet;\n",
        "  int arr_size=arr.size();\n",
        "  while(miSet.size()<s){\n",
        "    int r=rand()%arr_size;\n",
        "    miSet.insert(r);\n",
        "  }\n",
        "  for(int indice:miSet) ret.push_back(arr[indice]);\n",
        "  return ret;\n",
        "}\n",
        "\n",
        "vector<int> getPivotes(vector<int> &sample, int numPivotes){\n",
        "  int sample_size=sample.size();\n",
        "  vector<int> ret;\n",
        "  if(numPivotes==0||sample_size==0) return ret;\n",
        "  if(sample_size<=numPivotes) return ret;\n",
        "  for(int i=1;i<=numPivotes;i++){\n",
        "    int indice=i*sample_size/(numPivotes+1);\n",
        "    if(indice>=sample_size) indice=sample_size-1;\n",
        "    ret.push_back(sample[indice]);\n",
        "  }\n",
        "  return ret;\n",
        "}\n",
        "\n",
        "__global__ void assignToBuckets(int* arr, int* pivotes, int* bucket_ids, int size, int numPivotes){\n",
        "  int indice=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  if(indice>=size) return;\n",
        "  int val=arr[indice];\n",
        "  int inf=0,sup=numPivotes;\n",
        "  while(inf<sup){\n",
        "    int mid=(inf+sup)/2;\n",
        "    if(val<=pivotes[mid]) sup=mid;\n",
        "    else inf=mid+1;\n",
        "  }\n",
        "  bucket_ids[indice]=inf;\n",
        "}\n",
        "\n",
        "void sampleSort(vector<int> &arr, int p){\n",
        "  int arr_size=arr.size();\n",
        "  if(arr_size<=THRESHOLD){\n",
        "    sort(arr.begin(),arr.end());\n",
        "    return;\n",
        "  }\n",
        "  int s=getMin(arr_size,4*p*log2(arr_size));\n",
        "  vector<int> sample=randSample(arr,s);\n",
        "  if(sample.size()<=p-1){\n",
        "    sort(arr.begin(),arr.end());\n",
        "    return;\n",
        "  }\n",
        "  sort(sample.begin(),sample.end());\n",
        "  vector<int> pivotes=getPivotes(sample,p-1);\n",
        "  if(pivotes.empty()){\n",
        "    sort(arr.begin(),arr.end());\n",
        "    return;\n",
        "  }\n",
        "  thrust::device_vector<int> d_arr(arr.begin(),arr.end());\n",
        "  thrust::device_vector<int> d_pivotes(pivotes.begin(),pivotes.end());\n",
        "  thrust::device_vector<int> d_bucket_ids(arr_size);\n",
        "  int hebras=256;\n",
        "  int bloques=(arr_size+hebras-1)/hebras;\n",
        "  assignToBuckets<<<bloques,hebras>>>(\n",
        "    thrust::raw_pointer_cast(d_arr.data()),\n",
        "    thrust::raw_pointer_cast(d_pivotes.data()),\n",
        "    thrust::raw_pointer_cast(d_bucket_ids.data()),\n",
        "    arr_size,\n",
        "    p-1\n",
        "  );\n",
        "  cudaDeviceSynchronize();\n",
        "  thrust::stable_sort_by_key(d_bucket_ids.begin(),d_bucket_ids.end(),d_arr.begin());\n",
        "  thrust::device_vector<int> keys_out(p);\n",
        "  thrust::device_vector<int> counts(p);\n",
        "  auto rbk_end=thrust::reduce_by_key(\n",
        "    d_bucket_ids.begin(),\n",
        "    d_bucket_ids.end(),\n",
        "    thrust::constant_iterator<int>(1),\n",
        "    keys_out.begin(),\n",
        "    counts.begin()\n",
        "  );\n",
        "  int num_buckets=rbk_end.first-keys_out.begin();\n",
        "  thrust::device_vector<int> d_offsets(p+1);\n",
        "  d_offsets[0]=0;\n",
        "  thrust::inclusive_scan(\n",
        "    counts.begin(),\n",
        "    counts.begin()+num_buckets,\n",
        "    d_offsets.begin()+1\n",
        "  );\n",
        "  for(int i=0;i<num_buckets;i++){\n",
        "    int inicio=d_offsets[i];\n",
        "    int fin=d_offsets[i+1];\n",
        "    if(fin>inicio) thrust::sort(d_arr.begin()+inicio,d_arr.begin()+fin);\n",
        "  }\n",
        "  thrust::copy(d_arr.begin(),d_arr.end(),arr.begin());\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  srand(time(NULL));\n",
        "  int size=atoi(argv[1]),p=atoi(argv[2]);\n",
        "  vector<int> arr;\n",
        "  for(int i=0;i<size;i++) arr.push_back(1+rand()%200);\n",
        "  cout<<\"Arreglo inicial: \";\n",
        "  printArray(arr);\n",
        "  sampleSort(arr,p);\n",
        "  auto finish=chrono::high_resolution_clock::now();\n",
        "  auto duration=chrono::duration_cast<chrono::nanoseconds>(finish - start).count();\n",
        "  cout<<\"Tiempo demorado en ordenar arreglo: \"<<duration/1000000000.0<<\" s\\n\";\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pz5H-xegCaH",
        "outputId": "2d04d504-abae-4498-dfe7-be95ce87b948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sample_sort.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -O2 sample_sort.cu -o sample_sort"
      ],
      "metadata": {
        "id": "E5v05ZZs9S4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./sample_sort 64 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EEvGAGX-hN0",
        "outputId": "02e357c5-34e9-41dd-f67c-c751f91ff0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arreglo inicial: 121 125 122 65 9 25 176 145 17 43 22 148 13 198 112 61 37 116 136 5 198 111 135 18 105 127 98 177 160 66 93 32 190 166 96 150 190 24 46 158 18 68 58 30 65 169 90 54 36 177 58 33 39 144 3 96 22 100 72 182 165 116 165 107 \n",
            "Arreglo ordenado: 3 5 9 13 17 18 18 22 22 24 25 30 32 33 36 37 39 43 46 54 58 58 61 65 65 66 68 72 90 93 96 96 98 100 105 107 111 112 116 116 121 122 125 127 135 136 144 145 148 150 158 160 165 165 166 169 176 177 177 182 190 190 198 198 \n"
          ]
        }
      ]
    }
  ]
}