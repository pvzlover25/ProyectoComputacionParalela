{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq41Rfo4t-GX",
        "outputId": "45434a55-340d-48b1-859d-e9bfe4b5d25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        target. The options -dlto -arch=sm_NN will add a lto_NN target; if you want\n",
            "        to only add a lto_NN target and not the compute_NN that -arch=sm_NN usually\n",
            "        for '--gpu-architecture' may be a 'real' architecture (such as a sm_50),\n",
            "        --gpu-architecture=sm_50' is equivalent to 'nvcc --gpu-architecture=compute_50\n",
            "        --gpu-code=sm_50,compute_50'.\n",
            "        -arch=all         build for all supported architectures (sm_*), and add PTX\n",
            "        -arch=all-major   build for just supported major versions (sm_*0), plus the\n",
            "        -arch=native      build for all architectures (sm_*) on the current system\n",
            "        'native','sm_50','sm_52','sm_53','sm_60','sm_61','sm_62','sm_70','sm_72',\n",
            "        'sm_75','sm_80','sm_86','sm_87','sm_89','sm_90','sm_90a'.\n",
            "        (such as sm_50), and PTX code for the 'virtual' architecture (such as compute_50).\n",
            "        For instance, '--gpu-architecture=compute_60' is not compatible with '--gpu-code=sm_52',\n",
            "        features that are not present on 'sm_52'.\n",
            "        'lto_75','lto_80','lto_86','lto_87','lto_89','lto_90','lto_90a','sm_50',\n",
            "        'sm_52','sm_53','sm_60','sm_61','sm_62','sm_70','sm_72','sm_75','sm_80',\n",
            "        'sm_86','sm_87','sm_89','sm_90','sm_90a'.\n",
            "        List the non-accelerated gpu architectures (sm_XX) supported by the compiler\n"
          ]
        }
      ],
      "source": [
        "!nvcc --help | grep sm_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj_xB1U72ias",
        "outputId": "46070079-9570-4a9c-deca-62b23c3f42df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  8 16:24:56 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile merge_sort.cu\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "void printArray(int* arr, int size){\n",
        "  for(int i=0;i<size;i++) cout<<arr[i]<<\" \";\n",
        "  cout<<\"\\n\";\n",
        "}\n",
        "\n",
        "__global__ void merge(int* in, int* out, int width, int size){\n",
        "  int indice=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  int inicio=2*indice*width;\n",
        "  if(inicio>=size) return;\n",
        "  int mid=min(inicio+width,size),fin=min(inicio+2*width,size);\n",
        "  int i=inicio,j=mid,k=inicio;\n",
        "  while(i<mid && j<fin){\n",
        "    if(in[i]<=in[j]){\n",
        "      out[k]=in[i];\n",
        "      i++;\n",
        "    }else{\n",
        "      out[k]=in[j];\n",
        "      j++;\n",
        "    }\n",
        "    k++;\n",
        "  }\n",
        "  while(i<mid){\n",
        "    out[k]=in[i];\n",
        "    i++;\n",
        "    k++;\n",
        "  }\n",
        "  while(j<fin){\n",
        "    out[k]=in[j];\n",
        "    j++;\n",
        "    k++;\n",
        "  }\n",
        "}\n",
        "\n",
        "void mergeSort(int* arr, int size){\n",
        "  int *d_in,*d_out;\n",
        "  cudaMalloc(&d_in,size*sizeof(int));\n",
        "  cudaMalloc(&d_out,size*sizeof(int));\n",
        "  cudaMemcpy(d_in,arr,size*sizeof(int),cudaMemcpyHostToDevice);\n",
        "  int hebras=256;\n",
        "  for(int width=1;width<size;width*=2){\n",
        "    int bloques=(size+2*width*hebras-1)/(2*width*hebras);\n",
        "    merge<<<bloques,hebras>>>(d_in,d_out,width,size);\n",
        "    cudaDeviceSynchronize();\n",
        "    swap(d_in,d_out);\n",
        "  }\n",
        "  cudaMemcpy(arr,d_in,size*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  srand(time(NULL));\n",
        "  int size=atoi(argv[1]);\n",
        "  int* arr=new int[size];\n",
        "  for(int i=0;i<size;i++) arr[i]=1+rand()%200;\n",
        "  auto start=chrono::high_resolution_clock::now();\n",
        "  mergeSort(arr,size);\n",
        "  auto finish=chrono::high_resolution_clock::now();\n",
        "  auto duration=chrono::duration_cast<chrono::nanoseconds>(finish - start).count();\n",
        "  cout<<\"Tiempo demorado en ordenar arreglo: \"<<duration/1000000000.0<<\" s\\n\";\n",
        "  delete[] arr;\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMg2eURO2tsI",
        "outputId": "8acea9d0-a0ad-42d3-898e-012dd0952543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting merge_sort.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 merge_sort.cu -o merge_sort"
      ],
      "metadata": {
        "id": "BDWG3pi7ATFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./merge_sort 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewcHEJowBsxr",
        "outputId": "d00d8aa7-77fe-47c1-8311-1b1dca5f3701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo demorado en ordenar arreglo: 0.106912 s\n"
          ]
        }
      ]
    }
  ]
}