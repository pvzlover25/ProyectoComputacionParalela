{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlRjI69L9iZV",
        "outputId": "cd19669f-a7e1-44e7-a1e4-c3651c63c8cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        target. The options -dlto -arch=sm_NN will add a lto_NN target; if you want\n",
            "        to only add a lto_NN target and not the compute_NN that -arch=sm_NN usually\n",
            "        for '--gpu-architecture' may be a 'real' architecture (such as a sm_50),\n",
            "        --gpu-architecture=sm_50' is equivalent to 'nvcc --gpu-architecture=compute_50\n",
            "        --gpu-code=sm_50,compute_50'.\n",
            "        -arch=all         build for all supported architectures (sm_*), and add PTX\n",
            "        -arch=all-major   build for just supported major versions (sm_*0), plus the\n",
            "        -arch=native      build for all architectures (sm_*) on the current system\n",
            "        'native','sm_50','sm_52','sm_53','sm_60','sm_61','sm_62','sm_70','sm_72',\n",
            "        'sm_75','sm_80','sm_86','sm_87','sm_89','sm_90','sm_90a'.\n",
            "        (such as sm_50), and PTX code for the 'virtual' architecture (such as compute_50).\n",
            "        For instance, '--gpu-architecture=compute_60' is not compatible with '--gpu-code=sm_52',\n",
            "        features that are not present on 'sm_52'.\n",
            "        'lto_75','lto_80','lto_86','lto_87','lto_89','lto_90','lto_90a','sm_50',\n",
            "        'sm_52','sm_53','sm_60','sm_61','sm_62','sm_70','sm_72','sm_75','sm_80',\n",
            "        'sm_86','sm_87','sm_89','sm_90','sm_90a'.\n",
            "        List the non-accelerated gpu architectures (sm_XX) supported by the compiler\n"
          ]
        }
      ],
      "source": [
        "!nvcc --help | grep sm_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdZxCpBB9pw1",
        "outputId": "13b17f61-93f2-45cf-dfc8-768ba31cf061"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul  9 16:13:48 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile radix_sort.cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/scan.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "typedef unsigned int usi;\n",
        "typedef unsigned char uch;\n",
        "\n",
        "const int BITS=8;\n",
        "const int RADIO=1<<BITS;\n",
        "\n",
        "void printArray(usi* arr, int size){\n",
        "  for(int i=0;i<size;i++) cout<<arr[i]<<\" \";\n",
        "  cout<<\"\\n\";\n",
        "}\n",
        "\n",
        "__global__ void computarDigitos(usi* input, uch* digitos, int shift, int n){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  if(i<n) digitos[i]=(input[i]>>shift)&0xFF;\n",
        "}\n",
        "\n",
        "__global__ void histogramaKernel(uch* digitos, int* histograma, int n){\n",
        "  __shared__ int histLocal[RADIO];\n",
        "  int tid=threadIdx.x;\n",
        "  if(tid<RADIO) histLocal[tid]=0;\n",
        "  __syncthreads();\n",
        "  int i=blockIdx.x*blockDim.x+tid;\n",
        "  if(i<n) atomicAdd(&histLocal[digitos[i]],1);\n",
        "  __syncthreads();\n",
        "  if(tid<RADIO) atomicAdd(&histograma[tid],histLocal[tid]);\n",
        "}\n",
        "\n",
        "__global__ void reordenarKernel(usi* input, uch* digitos, int* digit_offsets,\n",
        " int* counters, usi* output, int n){\n",
        "  int i=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  if(i<n){\n",
        "    uch digito=digitos[i];\n",
        "    int pos=atomicAdd(&counters[digito],1);\n",
        "    output[digit_offsets[digito]+pos]=input[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "void radixSort(usi* d_input, usi* d_output, int n){\n",
        "  uch* d_digitos;\n",
        "  int* d_histograma;\n",
        "  int* d_pos;\n",
        "  int* d_counters;\n",
        "  cudaMalloc(&d_digitos, n*sizeof(uch));\n",
        "  cudaMalloc(&d_histograma, RADIO*sizeof(int));\n",
        "  cudaMalloc(&d_pos, RADIO*sizeof(int));\n",
        "  cudaMalloc(&d_counters, RADIO*sizeof(int));\n",
        "  dim3 bloque(256);\n",
        "  dim3 grid((n+bloque.x-1)/bloque.x);\n",
        "  for(int shift=0;shift<32;shift+=BITS){\n",
        "    computarDigitos<<<grid,bloque>>>(d_input,d_digitos,shift,n);\n",
        "    cudaMemset(d_histograma,0,RADIO*sizeof(int));\n",
        "    histogramaKernel<<<grid,bloque>>>(d_digitos,d_histograma,n);\n",
        "    thrust::device_ptr<int> hist_ptr(d_histograma);\n",
        "    thrust::device_ptr<int> pos_ptr(d_pos);\n",
        "    thrust::exclusive_scan(hist_ptr,hist_ptr+RADIO,pos_ptr);\n",
        "    cudaMemset(d_counters,0,RADIO*sizeof(int));\n",
        "    reordenarKernel<<<grid,bloque>>>(d_input,d_digitos,d_pos,d_counters,d_output,n);\n",
        "    swap(d_input,d_output);\n",
        "  }\n",
        "  cudaFree(d_digitos);\n",
        "  cudaFree(d_histograma);\n",
        "  cudaFree(d_pos);\n",
        "  cudaFree(d_counters);\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  srand(time(NULL));\n",
        "  int size=atoi(argv[1]);\n",
        "  usi* arr=new usi[size];\n",
        "  for(int i=0;i<size;i++) arr[i]=1+rand()%200;\n",
        "  cout<<\"Arreglo original: \";\n",
        "  printArray(arr,size);\n",
        "  usi *d_in,*d_out;\n",
        "  cudaMalloc(&d_in,size*sizeof(usi));\n",
        "  cudaMalloc(&d_out,size*sizeof(usi));\n",
        "  cudaMemcpy(d_in,arr,size*sizeof(usi),cudaMemcpyHostToDevice);\n",
        "  radixSort(d_in,d_out,size);\n",
        "  cudaMemcpy(arr,d_in,size*sizeof(usi),cudaMemcpyDeviceToHost);\n",
        "  cout<<\"Arreglo ordenado: \";\n",
        "  printArray(arr,size);\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "  delete[] arr;\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_YzjMEa9wJT",
        "outputId": "57f382dc-ea0a-41f4-f731-c8d33e605df4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting radix_sort.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 radix_sort.cu -o radix_sort"
      ],
      "metadata": {
        "id": "dsHuWaTuG-6D"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./radix_sort 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Oj1rzH6Ieb6",
        "outputId": "7f982d55-fc1e-4ff0-ce06-0014a4450973"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arreglo original: 22 21 181 97 195 157 76 69 65 168 \n",
            "Arreglo ordenado: 21 22 65 69 76 97 157 168 181 195 \n"
          ]
        }
      ]
    }
  ]
}